{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torchvision import transforms, models, datasets\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "from pylab import imread"
      ],
      "outputs": [],
      "metadata": {
        "id": "PIDNEoMIoA7q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "if (os.path.exists(\"./output\")) == False:\n",
        "    os.mkdir(\"output\")\n",
        "\n",
        "if (os.path.exists(\"./model_weight\")) == False:\n",
        "    os.mkdir(\"model_weight\")\n",
        "\n",
        "for epoch in range (200):\n",
        "    if (os.path.exists(\"./output/%03d\" % epoch)) == False:\n",
        "        os.mkdir(\"./output/%03d\" % epoch)\n",
        "    else:\n",
        "        files = glob.glob(\"./output/%03d/*.png\" % epoch)\n",
        "\n",
        "        for f in files:\n",
        "          os.remove(f)"
      ],
      "outputs": [],
      "metadata": {
        "id": "GjBJCEJeoA7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "kaErkB1roA7z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "kwargs = {'num_workers': 2, 'pin_memory': True}\n",
        "\n",
        "cuda = True\n",
        "image_size = 32\n",
        "batchSize = 64"
      ],
      "outputs": [],
      "metadata": {
        "id": "jFqUAOXUoA73"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "def show_img(source, target, source_label, target_label):\n",
        "    num_row = 4\n",
        "    num_col = 5\n",
        "    num = 10\n",
        "    images = source[:num]\n",
        "    labels = source_label[:num]\n",
        "\n",
        "    fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
        "    for i in range(num):\n",
        "        ax = axes[i//num_col, i%num_col]\n",
        "        \n",
        "        image =  images[i].transpose(0,2).transpose(0,1)\n",
        "\n",
        "        ax.imshow(image, cmap='gray')\n",
        "        ax.set_title('Label: {}'.format(labels[i]))\n",
        "\n",
        "\n",
        "    images = target[:num]\n",
        "    labels = target_label[:num]\n",
        "    for i in range(10,20):\n",
        "        ax = axes[i//num_col, i%num_col]\n",
        "        image = images[i - 10].transpose(0,2).transpose(0,1)\n",
        "        ax.imshow(image, cmap='gray')\n",
        "        ax.set_title('Label: {}'.format(labels[i - 10]))\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "-miReHhIoA75"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "transform = transforms.Compose([\n",
        "        transforms.Resize(image_size),\n",
        "        transforms.Grayscale(3),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Lambda(lambda t: t * 2 - 1)])\n",
        "\n",
        "mnist_trainset = datasets.MNIST(root='./data/mnist', train=True, download=True, transform=transform)\n",
        "mnist_testset = datasets.MNIST(root='./data/mnist', train=False, download=True, transform=transform)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "13as5mhOoA76"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "def get_backgrounds():\n",
        "    backgrounds = []\n",
        "    for file in os.listdir(\"./images/train\"):\n",
        "        if file.endswith('.jpg'):\n",
        "            backgrounds.append(plt.imread(os.path.join(\"./images/train\",file)))\n",
        "    return backgrounds\n",
        "\n",
        "def compose_image(image, backgrounds):\n",
        "    image = (image > 0).astype(np.float32)\n",
        "    image = image.reshape([28,28])*255.0\n",
        "    \n",
        "    image = np.stack([image,image,image],axis=2)\n",
        "    \n",
        "    background = np.random.choice(backgrounds)\n",
        "    w,h,_ = background.shape\n",
        "    dw, dh,_ = image.shape\n",
        "    x = np.random.randint(0,w-dw)\n",
        "    y = np.random.randint(0,h-dh)\n",
        "    \n",
        "    temp = background[x:x+dw, y:y+dh]\n",
        "    return np.abs(temp-image).astype(np.uint8)\n",
        "\n",
        "class MNISTM(Dataset):    \n",
        "    def __init__(self, train=True,transform=None):\n",
        "        if train:\n",
        "            self.data = datasets.MNIST(root='.data/mnist',train=True, download=True)\n",
        "        else:\n",
        "            self.data = datasets.MNIST(root='.data/mnist',train=False, download=True)\n",
        "        self.backgrounds = get_backgrounds()\n",
        "        self.transform = transform\n",
        "        self.images = []\n",
        "        self.targets = []\n",
        "        for index in range(len(self.data)):\n",
        "            image = np.array(self.data.__getitem__(index)[0])\n",
        "            target = self.data.__getitem__(index)[1]\n",
        "            image = compose_image(image, self.backgrounds)\n",
        "            if self.transform is not None:\n",
        "                image = self.transform(image)\n",
        "            self.images.append(image)\n",
        "            self.targets.append(target)\n",
        "        \n",
        "    def __getitem__(self,index):\n",
        "        image = self.images[index]\n",
        "        target = self.targets[index]\n",
        "        \n",
        "        return image, target\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "outputs": [],
      "metadata": {
        "id": "T9uUpScqoA77"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize(image_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Lambda(lambda t: t * 2 - 1)\n",
        "        ])\n",
        "\n",
        "trainset = MNISTM(train=True,transform=transform)\n",
        "testset = MNISTM(train=False,transform=transform)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        }
      ],
      "metadata": {
        "id": "V9N3L3UpoA79",
        "outputId": "7e895382-b860-4365-9fde-0600664eac8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "source": [
        "source_train = DataLoader(mnist_trainset, batch_size=batchSize, shuffle=True, drop_last=True, **kwargs)\n",
        "source_test = DataLoader(mnist_testset, batch_size=batchSize, shuffle=True, drop_last=True, **kwargs)\n",
        "\n",
        "target_train = DataLoader(trainset, batch_size=batchSize, shuffle=True, drop_last=True, **kwargs)\n",
        "target_test = DataLoader(testset, batch_size=batchSize, shuffle=False, drop_last=True, **kwargs)"
      ],
      "outputs": [],
      "metadata": {
        "id": "u3QsqRRIoA7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module"
      ],
      "metadata": {
        "id": "7BZ_W1dvoA7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_iter = iter(source_train)\n",
        "source_inputs, source_label = source_iter.next()\n",
        "\n",
        "target_iter = iter(target_train)\n",
        "target_inputs, target_label = target_iter.next()"
      ],
      "metadata": {
        "id": "UAP38dIJoHGq"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1, padding=1, dilation=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=padding, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None,\n",
        "                 dilation=(1, 1), residual=True):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride,\n",
        "                             padding=dilation[0], dilation=dilation[0])\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes,\n",
        "                             padding=dilation[1], dilation=dilation[1])\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.residual = residual\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "        if self.residual:\n",
        "            out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None,\n",
        "                 dilation=(1, 1), residual=True):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=dilation[1], bias=False,\n",
        "                               dilation=dilation[1])\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class DRN(nn.Module):\n",
        "    def __init__(self, block, layers, num_cls=19,\n",
        "                 channels=(16, 32, 64, 128, 256, 512, 512, 512),\n",
        "                 out_map=False, out_middle=False, pool_size=28,\n",
        "                 weights_init=None, pretrained=True, finetune=False,\n",
        "                 output_last_ft=False, modelname='drn26'):\n",
        "        if output_last_ft:\n",
        "            print('DRN discrim feat not implemented, using scores')\n",
        "\n",
        "        super(DRN, self).__init__()\n",
        "        self.inplanes = channels[0]\n",
        "        self.out_map = out_map\n",
        "        self.out_dim = channels[-1]\n",
        "        self.out_middle = out_middle\n",
        "        self.conv1 = nn.Conv2d(3, channels[0], kernel_size=7, stride=1, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(channels[0])\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.layer1 = self._make_layer(BasicBlock, channels[0], layers[0], stride=1)\n",
        "        self.layer2 = self._make_layer(BasicBlock, channels[1], layers[1], stride=2)\n",
        "\n",
        "        self.layer3 = self._make_layer(block, channels[2], layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, channels[3], layers[3], stride=2)\n",
        "        self.layer5 = self._make_layer(block, channels[4], layers[4], dilation=2,\n",
        "                                       new_level=False)\n",
        "        self.layer6 = None if layers[5] == 0 else \\\n",
        "            self._make_layer(block, channels[5], layers[5], dilation=4,\n",
        "                             new_level=False)\n",
        "        self.layer7 = None if layers[6] == 0 else \\\n",
        "            self._make_layer(BasicBlock, channels[6], layers[6], dilation=2,\n",
        "                             new_level=False, residual=False)\n",
        "        self.layer8 = None if layers[7] == 0 else \\\n",
        "            self._make_layer(BasicBlock, channels[7], layers[7], dilation=1,\n",
        "                             new_level=False, residual=False)\n",
        "\n",
        "        if num_cls > 0:\n",
        "            self.avgpool = nn.AvgPool2d(pool_size)\n",
        "            # self.fc = nn.Linear(self.out_dim, num_classes)\n",
        "            self.fc = nn.Conv2d(self.out_dim, num_cls, kernel_size=1,\n",
        "                                stride=1, padding=0, bias=True)\n",
        "       \n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1,\n",
        "                    new_level=True, residual=True):\n",
        "        assert dilation == 1 or dilation % 2 == 0\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(\n",
        "            self.inplanes, planes, stride, downsample,\n",
        "            dilation=(1, 1) if dilation == 1 else (\n",
        "                dilation // 2 if new_level else dilation, dilation),\n",
        "            residual=residual))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, residual=residual,\n",
        "                                dilation=(dilation, dilation)))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n"
      ],
      "metadata": {
        "id": "YZ3ldWn-oI-w"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_0 = nn.Sequential(\n",
        "    nn.Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False),\n",
        "    nn.BatchNorm2d(16),\n",
        "    nn.ReLU(inplace=True)\n",
        ")\n",
        "\n",
        "layer_1 = nn.Sequential(\n",
        "    nn.Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
        "    nn.BatchNorm2d(16),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
        "    nn.BatchNorm2d(16)\n",
        ")\n",
        "\n",
        "layer_2 = nn.Sequential(\n",
        "    nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
        "    nn.BatchNorm2d(32)\n",
        ")\n",
        "layer_2_downsample = nn.Sequential(\n",
        "    nn.Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
        "    nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        ")\n",
        "\n",
        "layer_3 = nn.Sequential(\n",
        "    nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "\n",
        "    nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(inplace=True),\n",
        "\n",
        "    nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        ")\n",
        "\n",
        "layer_3_downsample = nn.Sequential(\n",
        "    nn.Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
        "    nn.BatchNorm2d(64)\n",
        ")\n",
        "\n",
        "layer_4 = nn.Sequential(\n",
        "    nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "\n",
        "    nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(inplace=True),\n",
        "\n",
        "    nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        ")\n",
        "\n",
        "layer_4_downsample = nn.Sequential(\n",
        "    nn.Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False),\n",
        "    nn.BatchNorm2d(128)\n",
        ")\n",
        "\n",
        "layer_5 = nn.Sequential(\n",
        "    nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "\n",
        "    nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(inplace=True),\n",
        "\n",
        "    nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        ")\n",
        "\n",
        "layer_5_downsample = nn.Sequential(\n",
        "    nn.Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
        "    nn.BatchNorm2d(256)\n",
        ")\n",
        "\n",
        "layer_6 = nn.Sequential(\n",
        "    nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "\n",
        "    nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ReLU(inplace=True),\n",
        "\n",
        "    nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        ")\n",
        "\n",
        "layer_6_downsample = nn.Sequential(\n",
        "    nn.Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
        "    nn.BatchNorm2d(512)\n",
        ")\n",
        "\n",
        "layer_7 = nn.Sequential(\n",
        "    nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False),\n",
        "    nn.BatchNorm2d(512)\n",
        ")\n"
      ],
      "metadata": {
        "id": "IcXU7qsuoumT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DRN(BasicBlock, [1, 1, 2, 2, 2, 2, 1, 1], modelname='drn26', out_map=True, finetune=None)"
      ],
      "metadata": {
        "id": "Pi8_jo1WoWnw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "k_YPYyjhoqfG",
        "outputId": "95268228-edf7-4c26-e6b0-c7bbdd1a5a32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DRN(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer5): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer6): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer7): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer8): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AvgPool2d(kernel_size=28, stride=28, padding=0)\n",
              "  (fc): Conv2d(512, 19, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zUcak6iXotDX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "third.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}