{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import transforms, models, datasets\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from pylab import imread"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if (os.path.exists(\"./output\")) == False:\n",
    "    os.mkdir(\"output\")\n",
    "\n",
    "if (os.path.exists(\"./model_weight\")) == False:\n",
    "    os.mkdir(\"model_weight\")\n",
    "\n",
    "for epoch in range (200):\n",
    "    if (os.path.exists(\"./output/%03d\" % epoch)) == False:\n",
    "        os.mkdir(\"./output/%03d\" % epoch)\n",
    "    else:\n",
    "        files = glob.glob(\"./output/%03d/*.png\" % epoch)\n",
    "\n",
    "        for f in files:\n",
    "          os.remove(f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True}\n",
    "\n",
    "cuda = True\n",
    "image_size = 32\n",
    "batchSize = 64"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def show_img(source, target, source_label, target_label):\n",
    "    num_row = 4\n",
    "    num_col = 5\n",
    "    num = 10\n",
    "    images = source[:num]\n",
    "    labels = source_label[:num]\n",
    "\n",
    "    fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "    for i in range(num):\n",
    "        ax = axes[i//num_col, i%num_col]\n",
    "        \n",
    "        image =  images[i].transpose(0,2).transpose(0,1)\n",
    "\n",
    "        ax.imshow(image, cmap='gray')\n",
    "        ax.set_title('Label: {}'.format(labels[i]))\n",
    "\n",
    "\n",
    "    images = target[:num]\n",
    "    labels = target_label[:num]\n",
    "    for i in range(10,20):\n",
    "        ax = axes[i//num_col, i%num_col]\n",
    "        image = images[i - 10].transpose(0,2).transpose(0,1)\n",
    "        ax.imshow(image, cmap='gray')\n",
    "        ax.set_title('Label: {}'.format(labels[i - 10]))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.Grayscale(3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda t: t * 2 - 1)])\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data/mnist', train=True, download=True, transform=transform)\n",
    "mnist_testset = datasets.MNIST(root='./data/mnist', train=False, download=True, transform=transform)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_backgrounds():\n",
    "    backgrounds = []\n",
    "    for file in os.listdir(\"./images/train\"):\n",
    "        if file.endswith('.jpg'):\n",
    "            backgrounds.append(plt.imread(os.path.join(\"./images/train\",file)))\n",
    "    return backgrounds\n",
    "\n",
    "def compose_image(image, backgrounds):\n",
    "    image = (image > 0).astype(np.float32)\n",
    "    image = image.reshape([28,28])*255.0\n",
    "    \n",
    "    image = np.stack([image,image,image],axis=2)\n",
    "    \n",
    "    background = np.random.choice(backgrounds)\n",
    "    w,h,_ = background.shape\n",
    "    dw, dh,_ = image.shape\n",
    "    x = np.random.randint(0,w-dw)\n",
    "    y = np.random.randint(0,h-dh)\n",
    "    \n",
    "    temp = background[x:x+dw, y:y+dh]\n",
    "    return np.abs(temp-image).astype(np.uint8)\n",
    "\n",
    "class MNISTM(Dataset):    \n",
    "    def __init__(self, train=True,transform=None):\n",
    "        if train:\n",
    "            self.data = datasets.MNIST(root='.data/mnist',train=True, download=True)\n",
    "        else:\n",
    "            self.data = datasets.MNIST(root='.data/mnist',train=False, download=True)\n",
    "        self.backgrounds = get_backgrounds()\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.targets = []\n",
    "        for index in range(len(self.data)):\n",
    "            image = np.array(self.data.__getitem__(index)[0])\n",
    "            target = self.data.__getitem__(index)[1]\n",
    "            image = compose_image(image, self.backgrounds)\n",
    "            if self.transform is not None:\n",
    "                image = self.transform(image)\n",
    "            self.images.append(image)\n",
    "            self.targets.append(target)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        image = self.images[index]\n",
    "        target = self.targets[index]\n",
    "        \n",
    "        return image, target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda t: t * 2 - 1)\n",
    "        ])\n",
    "\n",
    "trainset = MNISTM(train=True,transform=transform)\n",
    "testset = MNISTM(train=False,transform=transform)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "source_train = DataLoader(mnist_trainset, batch_size=batchSize, shuffle=True, drop_last=True, **kwargs)\n",
    "source_test = DataLoader(mnist_testset, batch_size=batchSize, shuffle=True, drop_last=True, **kwargs)\n",
    "\n",
    "target_train = DataLoader(trainset, batch_size=batchSize, shuffle=True, drop_last=True, **kwargs)\n",
    "target_test = DataLoader(testset, batch_size=batchSize, shuffle=False, drop_last=True, **kwargs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Module"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Mixer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mixer, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(3, 64, 7),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.filter = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(64, 3, 7),\n",
    "            nn.InstanceNorm2d(3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, A, B):\n",
    "        encode_A = self.encoder(A)\n",
    "        encode_B = self.encoder(B)\n",
    "\n",
    "        reconA = self.decoder(encode_A)\n",
    "        reconB = self.decoder(encode_B)\n",
    "\n",
    "        encode_A.detach()\n",
    "        encode_B.detach()\n",
    "\n",
    "        mixed_latent = torch.cat([encode_A, encode_B], dim=1)\n",
    "        mixed_image = self.filter(mixed_latent)\n",
    "        new_image = self.decoder(mixed_image)\n",
    "        \n",
    "        return new_image, reconA, reconB"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_nc = 3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(input_nc, 64, 4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 128, 4, padding=1),\n",
    "            nn.InstanceNorm2d(128), \n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 256, 4, padding=1),\n",
    "            nn.InstanceNorm2d(256), \n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 1, 4, padding=1)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x =  self.model(x)\n",
    "        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "source_iter = iter(source_train)\n",
    "source_inputs, source_label = source_iter.next()\n",
    "\n",
    "target_iter = iter(target_train)\n",
    "target_inputs, target_label = target_iter.next()\n",
    "\n",
    "test_tensor_source = source_inputs\n",
    "test_tensor_target = target_inputs\n",
    "\n",
    "perceptual = Mixer()\n",
    "encoder = perceptual.encoder\n",
    "decoder = perceptual.decoder\n",
    "encoder_out = encoder(test_tensor_target)\n",
    "decoder_out = decoder(encoder_out)\n",
    "\n",
    "print(encoder_out.size())\n",
    "print(decoder_out.size())\n",
    "\n",
    "mixed, reconA, reconB = perceptual(test_tensor_source, test_tensor_target)\n",
    "print(mixed.size())\n",
    "print(reconA.size())\n",
    "print(reconB.size())\n",
    "\n",
    "print(\"mixed: min: %.2f, max: %.2f \" % (torch.min(mixed), torch.max(mixed)))\n",
    "print(\"reconA: min: %.2f, max: %.2f \" % (torch.min(reconA), torch.max(reconA)))\n",
    "print(\"reconB: min: %.2f, max: %.2f \" % (torch.min(reconB), torch.max(reconB)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loss"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def tv_loss(img, tv_weight=5e-2):\n",
    "    w_variance = torch.sum(torch.pow(img[:,:,:,:-1] - img[:,:,:,1:], 2))\n",
    "    h_variance = torch.sum(torch.pow(img[:,:,:-1,:] - img[:,:,1:,:], 2))\n",
    "    loss = tv_weight * (h_variance + w_variance)\n",
    "    return loss\n",
    "\n",
    "def total_variation_loss(img, weight=5e-2):\n",
    "    bs_img, c_img, h_img, w_img = img.size()\n",
    "    tv_h = torch.pow(img[:, :, 1:, :] - img[:, :, :-1, :], 2).sum()\n",
    "    tv_w = torch.pow(img[:, :, :, 1:] - img[:, :, :, :-1], 2).sum()\n",
    "    return weight * (tv_h + tv_w) / (bs_img * c_img * h_img * w_img)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mixer = Mixer()\n",
    "discriminator = Discriminator()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "learning_rate = 0.05\n",
    "beta = (0.5, 0.999)\n",
    "\n",
    "criterion_adv = torch.nn.MSELoss()\n",
    "criterion_discriminator = torch.nn.MSELoss()\n",
    "criterion_construct = torch.nn.L1Loss()\n",
    "\n",
    "optimizer_mix = torch.optim.Adam(mixer.parameters(), lr=learning_rate, betas=beta)\n",
    "optimizer_dis = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas=beta)\n",
    "\n",
    "scheduler_mix = StepLR(optimizer_mix, step_size=10, gamma=0.4)\n",
    "scheduler_dis = StepLR(optimizer_dis, step_size=10, gamma=0.4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if (torch.cuda.is_available()):\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    criterion_construct = criterion_construct.cuda()\n",
    "    criterion_discriminator = criterion_discriminator.cuda()\n",
    "    criterion_construct = criterion_construct.cuda()\n",
    "\n",
    "    mixer.cuda()\n",
    "    discriminator.cuda()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant(m.bias.data, 0.0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mixer.apply(weights_init_normal)\n",
    "discriminator.apply(weights_init_normal)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
    "real_label = Variable(Tensor(batchSize).fill_(1.0), requires_grad=False)\n",
    "fake_label = Variable(Tensor(batchSize).fill_(0.0), requires_grad=False)\n",
    "real_label = real_label[:, None]\n",
    "fake_label = fake_label[:, None]\n",
    "\n",
    "input_s = Tensor(batchSize, 3, image_size, image_size)\n",
    "input_t = Tensor(batchSize, 3, image_size, image_size)\n",
    "\n",
    "if cuda:\n",
    "  input_s, input_t = input_s.cuda(), input_t.cuda()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Mixed image will have same label with source\n",
    "def training(source, target, mixer, discriminator, \n",
    "             critic_adv, cirtic_recon, cirtic_dis, \n",
    "             optim_mix, optim_dis, \n",
    "             sche_mix, sche_dis, \n",
    "             use_cuda = True):\n",
    "    source_iter = iter(source)\n",
    "    target_iter = iter(target)\n",
    "\n",
    "    len_dataloader = min(len(source_iter), len(target_iter))\n",
    "\n",
    "    i = 0\n",
    "    while i < len_dataloader:\n",
    "        s_img, _ = source_iter.next()\n",
    "        t_img, _ = target_iter.next()\n",
    "\n",
    "        if use_cuda:\n",
    "            s_img, t_img = s_img.cuda(), t_img.cuda()\n",
    "\n",
    "        org_s = Variable(input_s.copy_(s_img))\n",
    "        org_t = Variable(input_t.copy_(t_img))\n",
    "\n",
    "        # Mixer\n",
    "        optim_mix.zero_grad()\n",
    "        mixed, recon_s, recon_t = mixer(org_s, org_t)\n",
    "        mixed_label = discriminator(mixed)\n",
    "\n",
    "        loss_ss = cirtic_recon(recon_s, org_s) * 5.0\n",
    "        loss_tt = cirtic_recon(recon_t, org_t) * 5.0\n",
    "\n",
    "        # if the discriminator predit false, loss_adv will decrease\n",
    "        loss_adv = critic_adv(mixed_label, real_label)\n",
    "        TV_loss = total_variation_loss(mixed)\n",
    "\n",
    "        mixer_loss = loss_ss + loss_tt + loss_adv + TV_loss\n",
    "        mixer_loss.backward()\n",
    "        optim_mix.step()\n",
    "\n",
    "        # Discriminator\n",
    "        optim_dis.zero_grad()\n",
    "\n",
    "        pred_real = discriminator(org_s)\n",
    "        pred_fake = discriminator(mixed.detach())\n",
    "\n",
    "        loss_dis_real = cirtic_dis(pred_real, real_label)\n",
    "        loss_dis_fake = cirtic_dis(pred_fake, fake_label)\n",
    "\n",
    "        discriminator_loss = loss_dis_real + loss_dis_fake\n",
    "        discriminator_loss.backward()\n",
    "        optim_dis.step()\n",
    "\n",
    "        if  i % 400 == 0:\n",
    "            real_A = org_s.data\n",
    "            real_B = org_t.data\n",
    "            mixed_image = mixed.data\n",
    "            reconstructionA = recon_s.data\n",
    "            reconstructionB = recon_t.data\n",
    "\n",
    "            save_image(real_A, './output/%03d/%d_A.png' % ( epoch, i))\n",
    "            save_image(real_B, 'output/%03d/%d_B.png' % ( epoch, i))\n",
    "            save_image(reconstructionA, 'output/%03d/%d_reconA.png' % ( epoch, i))\n",
    "            save_image(reconstructionB, 'output/%03d/%d_reconB.png' % ( epoch, i))\n",
    "            save_image(mixed_image, 'output/%03d/%d_Mixed.png' % ( epoch, i))\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    print (\"e: %d\" % epoch)    \n",
    "    print (\"mixer_loss: %.2f, loss_ss: %.2f, loss_tt: %.2f, loss_adv: %.2f\" % (mixer_loss, loss_ss, loss_tt, loss_adv))\n",
    "    print (\"discriminator_loss: %.2f, D_real: %.2f, D_fake: %.2f\" % (discriminator_loss, loss_dis_real, loss_dis_fake))\n",
    "\n",
    "    sche_mix.step()\n",
    "    sche_dis.step()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for epoch in range(0, 200):\n",
    "  training(source_train, target_train, mixer, discriminator, \n",
    "           criterion_adv, criterion_construct, criterion_discriminator, \n",
    "           optimizer_mix, optimizer_dis, \n",
    "           scheduler_mix, scheduler_dis, use_cuda = True)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}